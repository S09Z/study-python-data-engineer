{"cells":[{"cell_type":"code","execution_count":2,"id":"cf7cafb7","metadata":{},"outputs":[],"source":["df_yield = spark.read.format(\"jdbc\") \\\n","                     .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n","                     .option(\"url\", \"jdbc:mysql://116.204.183.76:13306/yield\") \\\n","                     .option(\"user\", \"cube_user\") \\\n","                     .option(\"password\", \"cu6euser\") \\\n","                     .option(\"dbtable\", \"yield_data\") \\\n","                     .load()"]},{"cell_type":"code","execution_count":4,"id":"bb79898e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>summary</th>\n","      <th>Area</th>\n","      <th>Item</th>\n","      <th>Year</th>\n","      <th>hg/ha_yield</th>\n","      <th>average_rain_fall_mm_per_year</th>\n","      <th>pesticides_tonnes</th>\n","      <th>avg_temp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>count</td>\n","      <td>28242</td>\n","      <td>28242</td>\n","      <td>28242</td>\n","      <td>28242</td>\n","      <td>28242</td>\n","      <td>28242</td>\n","      <td>28242</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>mean</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>2001.5442957297641</td>\n","      <td>77053.33209404434</td>\n","      <td>1149.055980454642</td>\n","      <td>37076.909343529136</td>\n","      <td>20.542626584519553</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>stddev</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>7.0519052853951205</td>\n","      <td>84956.61289666739</td>\n","      <td>709.8121499492227</td>\n","      <td>59958.78466505776</td>\n","      <td>6.312050836049751</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>min</td>\n","      <td>Albania</td>\n","      <td>Cassava</td>\n","      <td>1990</td>\n","      <td>50</td>\n","      <td>51.0</td>\n","      <td>0.04</td>\n","      <td>1.3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>25%</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>1995</td>\n","      <td>19910</td>\n","      <td>593.0</td>\n","      <td>1702.0</td>\n","      <td>16.7</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>50%</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>2001</td>\n","      <td>38295</td>\n","      <td>1083.0</td>\n","      <td>17517.76</td>\n","      <td>21.51</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>75%</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>2008</td>\n","      <td>104537</td>\n","      <td>1668.0</td>\n","      <td>48687.88</td>\n","      <td>26.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>max</td>\n","      <td>Zimbabwe</td>\n","      <td>Yams</td>\n","      <td>2013</td>\n","      <td>501412</td>\n","      <td>3240.0</td>\n","      <td>367778.0</td>\n","      <td>30.65</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  summary      Area     Item                Year        hg/ha_yield  \\\n","0   count     28242    28242               28242              28242   \n","1    mean      None     None  2001.5442957297641  77053.33209404434   \n","2  stddev      None     None  7.0519052853951205  84956.61289666739   \n","3     min   Albania  Cassava                1990                 50   \n","4     25%      None     None                1995              19910   \n","5     50%      None     None                2001              38295   \n","6     75%      None     None                2008             104537   \n","7     max  Zimbabwe     Yams                2013             501412   \n","\n","  average_rain_fall_mm_per_year   pesticides_tonnes            avg_temp  \n","0                         28242               28242               28242  \n","1             1149.055980454642  37076.909343529136  20.542626584519553  \n","2             709.8121499492227   59958.78466505776   6.312050836049751  \n","3                          51.0                0.04                 1.3  \n","4                         593.0              1702.0                16.7  \n","5                        1083.0            17517.76               21.51  \n","6                        1668.0            48687.88                26.0  \n","7                        3240.0            367778.0               30.65  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_yield.summary().toPandas()"]},{"cell_type":"code","execution_count":5,"id":"6b8ce021","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Item</th>\n","      <th>Year</th>\n","      <th>hg/ha_yield</th>\n","      <th>average_rain_fall_mm_per_year</th>\n","      <th>pesticides_tonnes</th>\n","      <th>avg_temp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Albania</td>\n","      <td>Maize</td>\n","      <td>1990</td>\n","      <td>36613</td>\n","      <td>1485.0</td>\n","      <td>121.0</td>\n","      <td>16.37</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1990</td>\n","      <td>66667</td>\n","      <td>1485.0</td>\n","      <td>121.0</td>\n","      <td>16.37</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Albania</td>\n","      <td>Rice, paddy</td>\n","      <td>1990</td>\n","      <td>23333</td>\n","      <td>1485.0</td>\n","      <td>121.0</td>\n","      <td>16.37</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Albania</td>\n","      <td>Sorghum</td>\n","      <td>1990</td>\n","      <td>12500</td>\n","      <td>1485.0</td>\n","      <td>121.0</td>\n","      <td>16.37</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Albania</td>\n","      <td>Soybeans</td>\n","      <td>1990</td>\n","      <td>7000</td>\n","      <td>1485.0</td>\n","      <td>121.0</td>\n","      <td>16.37</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Albania</td>\n","      <td>Wheat</td>\n","      <td>1990</td>\n","      <td>30197</td>\n","      <td>1485.0</td>\n","      <td>121.0</td>\n","      <td>16.37</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Albania</td>\n","      <td>Maize</td>\n","      <td>1991</td>\n","      <td>29068</td>\n","      <td>1485.0</td>\n","      <td>121.0</td>\n","      <td>15.36</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1991</td>\n","      <td>77818</td>\n","      <td>1485.0</td>\n","      <td>121.0</td>\n","      <td>15.36</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Albania</td>\n","      <td>Rice, paddy</td>\n","      <td>1991</td>\n","      <td>28538</td>\n","      <td>1485.0</td>\n","      <td>121.0</td>\n","      <td>15.36</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Albania</td>\n","      <td>Sorghum</td>\n","      <td>1991</td>\n","      <td>6667</td>\n","      <td>1485.0</td>\n","      <td>121.0</td>\n","      <td>15.36</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Area         Item  Year  hg/ha_yield  average_rain_fall_mm_per_year  \\\n","0  Albania        Maize  1990        36613                         1485.0   \n","1  Albania     Potatoes  1990        66667                         1485.0   \n","2  Albania  Rice, paddy  1990        23333                         1485.0   \n","3  Albania      Sorghum  1990        12500                         1485.0   \n","4  Albania     Soybeans  1990         7000                         1485.0   \n","5  Albania        Wheat  1990        30197                         1485.0   \n","6  Albania        Maize  1991        29068                         1485.0   \n","7  Albania     Potatoes  1991        77818                         1485.0   \n","8  Albania  Rice, paddy  1991        28538                         1485.0   \n","9  Albania      Sorghum  1991         6667                         1485.0   \n","\n","   pesticides_tonnes  avg_temp  \n","0              121.0     16.37  \n","1              121.0     16.37  \n","2              121.0     16.37  \n","3              121.0     16.37  \n","4              121.0     16.37  \n","5              121.0     16.37  \n","6              121.0     15.36  \n","7              121.0     15.36  \n","8              121.0     15.36  \n","9              121.0     15.36  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_yield.limit(10).toPandas()"]},{"cell_type":"code","execution_count":7,"id":"e281db07","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 7:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+--------------------+-----+\n","|                Item|count|\n","+--------------------+-----+\n","|            Potatoes| 4276|\n","|             Sorghum| 3039|\n","|               Maize| 4121|\n","|Plantains and others|  556|\n","|            Soybeans| 3223|\n","|               Wheat| 3857|\n","|         Rice, paddy| 3388|\n","|                Yams|  847|\n","|      Sweet potatoes| 2890|\n","|             Cassava| 2045|\n","+--------------------+-----+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df_yield.groupBy(\"Item\").count().show()"]},{"cell_type":"code","execution_count":8,"id":"a705d5d0","metadata":{},"outputs":[],"source":["df2 = df_yield[df_yield.Item == \"Potatoes\"] ## Filter Item \"Potatoes\""]},{"cell_type":"code","execution_count":10,"id":"c4df8bd6","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["4276"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df2.count()"]},{"cell_type":"code","execution_count":11,"id":"4fd3bddc","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Item</th>\n","      <th>Year</th>\n","      <th>hg/ha_yield</th>\n","      <th>average_rain_fall_mm_per_year</th>\n","      <th>pesticides_tonnes</th>\n","      <th>avg_temp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1990</td>\n","      <td>66667</td>\n","      <td>1485.0</td>\n","      <td>121.00</td>\n","      <td>16.37</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1991</td>\n","      <td>77818</td>\n","      <td>1485.0</td>\n","      <td>121.00</td>\n","      <td>15.36</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1992</td>\n","      <td>82920</td>\n","      <td>1485.0</td>\n","      <td>121.00</td>\n","      <td>16.06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1993</td>\n","      <td>98446</td>\n","      <td>1485.0</td>\n","      <td>121.00</td>\n","      <td>16.05</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1994</td>\n","      <td>81404</td>\n","      <td>1485.0</td>\n","      <td>201.00</td>\n","      <td>16.96</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1995</td>\n","      <td>111323</td>\n","      <td>1485.0</td>\n","      <td>251.00</td>\n","      <td>15.67</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1996</td>\n","      <td>106138</td>\n","      <td>1485.0</td>\n","      <td>313.96</td>\n","      <td>15.64</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1997</td>\n","      <td>109874</td>\n","      <td>1485.0</td>\n","      <td>376.93</td>\n","      <td>15.90</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1998</td>\n","      <td>127212</td>\n","      <td>1485.0</td>\n","      <td>439.89</td>\n","      <td>16.27</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1999</td>\n","      <td>142018</td>\n","      <td>1485.0</td>\n","      <td>502.86</td>\n","      <td>16.57</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Area      Item  Year  hg/ha_yield  average_rain_fall_mm_per_year  \\\n","0  Albania  Potatoes  1990        66667                         1485.0   \n","1  Albania  Potatoes  1991        77818                         1485.0   \n","2  Albania  Potatoes  1992        82920                         1485.0   \n","3  Albania  Potatoes  1993        98446                         1485.0   \n","4  Albania  Potatoes  1994        81404                         1485.0   \n","5  Albania  Potatoes  1995       111323                         1485.0   \n","6  Albania  Potatoes  1996       106138                         1485.0   \n","7  Albania  Potatoes  1997       109874                         1485.0   \n","8  Albania  Potatoes  1998       127212                         1485.0   \n","9  Albania  Potatoes  1999       142018                         1485.0   \n","\n","   pesticides_tonnes  avg_temp  \n","0             121.00     16.37  \n","1             121.00     15.36  \n","2             121.00     16.06  \n","3             121.00     16.05  \n","4             201.00     16.96  \n","5             251.00     15.67  \n","6             313.96     15.64  \n","7             376.93     15.90  \n","8             439.89     16.27  \n","9             502.86     16.57  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df2.limit(10).toPandas()"]},{"cell_type":"code","execution_count":14,"id":"c2bdfe04","metadata":{},"outputs":[{"data":{"text/plain":["'Area'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df2.columns[0]"]},{"cell_type":"code","execution_count":42,"id":"6a5bab1e","metadata":{},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.clustering import KMeans\n","from pyspark.ml.evaluation import ClusteringEvaluator\n","from pyspark.sql.functions import *"]},{"cell_type":"code","execution_count":133,"id":"3bf8d1d2","metadata":{},"outputs":[],"source":["# Step 1: define columns as a features\n","assemble = VectorAssembler(\n","    inputCols = df2.columns[3:7],\n","    outputCol = \"features\"\n",")"]},{"cell_type":"code","execution_count":134,"id":"7ca8bb5c","metadata":{},"outputs":[],"source":["train_data = assemble.transform(df2)"]},{"cell_type":"code","execution_count":23,"id":"e32888da","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Item</th>\n","      <th>Year</th>\n","      <th>hg/ha_yield</th>\n","      <th>average_rain_fall_mm_per_year</th>\n","      <th>pesticides_tonnes</th>\n","      <th>avg_temp</th>\n","      <th>features</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1990</td>\n","      <td>66667</td>\n","      <td>1485.0</td>\n","      <td>121.00</td>\n","      <td>16.37</td>\n","      <td>[66667.0, 1485.0, 121.0, 16.37]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1991</td>\n","      <td>77818</td>\n","      <td>1485.0</td>\n","      <td>121.00</td>\n","      <td>15.36</td>\n","      <td>[77818.0, 1485.0, 121.0, 15.36]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1992</td>\n","      <td>82920</td>\n","      <td>1485.0</td>\n","      <td>121.00</td>\n","      <td>16.06</td>\n","      <td>[82920.0, 1485.0, 121.0, 16.06]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1993</td>\n","      <td>98446</td>\n","      <td>1485.0</td>\n","      <td>121.00</td>\n","      <td>16.05</td>\n","      <td>[98446.0, 1485.0, 121.0, 16.05]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1994</td>\n","      <td>81404</td>\n","      <td>1485.0</td>\n","      <td>201.00</td>\n","      <td>16.96</td>\n","      <td>[81404.0, 1485.0, 201.0, 16.96]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1995</td>\n","      <td>111323</td>\n","      <td>1485.0</td>\n","      <td>251.00</td>\n","      <td>15.67</td>\n","      <td>[111323.0, 1485.0, 251.0, 15.67]</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1996</td>\n","      <td>106138</td>\n","      <td>1485.0</td>\n","      <td>313.96</td>\n","      <td>15.64</td>\n","      <td>[106138.0, 1485.0, 313.96, 15.64]</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1997</td>\n","      <td>109874</td>\n","      <td>1485.0</td>\n","      <td>376.93</td>\n","      <td>15.90</td>\n","      <td>[109874.0, 1485.0, 376.93, 15.9]</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1998</td>\n","      <td>127212</td>\n","      <td>1485.0</td>\n","      <td>439.89</td>\n","      <td>16.27</td>\n","      <td>[127212.0, 1485.0, 439.89, 16.27]</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Albania</td>\n","      <td>Potatoes</td>\n","      <td>1999</td>\n","      <td>142018</td>\n","      <td>1485.0</td>\n","      <td>502.86</td>\n","      <td>16.57</td>\n","      <td>[142018.0, 1485.0, 502.86, 16.57]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Area      Item  Year  hg/ha_yield  average_rain_fall_mm_per_year  \\\n","0  Albania  Potatoes  1990        66667                         1485.0   \n","1  Albania  Potatoes  1991        77818                         1485.0   \n","2  Albania  Potatoes  1992        82920                         1485.0   \n","3  Albania  Potatoes  1993        98446                         1485.0   \n","4  Albania  Potatoes  1994        81404                         1485.0   \n","5  Albania  Potatoes  1995       111323                         1485.0   \n","6  Albania  Potatoes  1996       106138                         1485.0   \n","7  Albania  Potatoes  1997       109874                         1485.0   \n","8  Albania  Potatoes  1998       127212                         1485.0   \n","9  Albania  Potatoes  1999       142018                         1485.0   \n","\n","   pesticides_tonnes  avg_temp                           features  \n","0             121.00     16.37    [66667.0, 1485.0, 121.0, 16.37]  \n","1             121.00     15.36    [77818.0, 1485.0, 121.0, 15.36]  \n","2             121.00     16.06    [82920.0, 1485.0, 121.0, 16.06]  \n","3             121.00     16.05    [98446.0, 1485.0, 121.0, 16.05]  \n","4             201.00     16.96    [81404.0, 1485.0, 201.0, 16.96]  \n","5             251.00     15.67   [111323.0, 1485.0, 251.0, 15.67]  \n","6             313.96     15.64  [106138.0, 1485.0, 313.96, 15.64]  \n","7             376.93     15.90   [109874.0, 1485.0, 376.93, 15.9]  \n","8             439.89     16.27  [127212.0, 1485.0, 439.89, 16.27]  \n","9             502.86     16.57  [142018.0, 1485.0, 502.86, 16.57]  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["train_data.limit(10).toPandas()"]},{"cell_type":"code","execution_count":129,"id":"d84e4c4e","metadata":{},"outputs":[{"data":{"text/plain":["10"]},"execution_count":129,"metadata":{},"output_type":"execute_result"}],"source":["#Step 2: set k-means\n","km = KMeans(k=3)\n","km.setSeed(2)\n","km.setWeightCol(\"Item\")\n","km.setMaxIter(10)\n","km.getMaxIter()"]},{"cell_type":"code","execution_count":135,"id":"23ae4ab1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/03/10 05:07:13 ERROR Instrumentation: org.apache.spark.sql.AnalysisException: Column 'Item' does not exist. Did you mean one of the following? [date, features, station_id, sensor_value3];\n","'Project [features#2864, unresolvedalias(UDF(cast('Item as double)), Some(org.apache.spark.sql.Column$$Lambda$4709/0x0000000101b8d040@13a20f83))]\n","+- Project [date#2560, sensor_value3#2538, station_id#2552, UDF(struct()) AS features#2864]\n","   +- Project [to_timestamp(date#2556, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC)) AS date#2560, sensor_value3#2538, station_id#2552]\n","      +- Project [cast(date#2548 as timestamp) AS date#2556, sensor_value3#2538, station_id#2552]\n","         +- Project [date#2548, sensor_value3#2538, cast(station_id#2543 as int) AS station_id#2552]\n","            +- Project [cast(date#2537 as timestamp) AS date#2548, sensor_value3#2538, station_id#2543]\n","               +- Project [date#2537, sensor_value3#2538, cast(station_id#2539 as int) AS station_id#2543]\n","                  +- Relation [date#2537,sensor_value3#2538,station_id#2539] json\n","\n","\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:54)\n","\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$7(CheckAnalysis.scala:200)\n","\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$7$adapted(CheckAnalysis.scala:193)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:367)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n","\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n","\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n","\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n","\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n","\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n","\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n","\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n","\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n","\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n","\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n","\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n","\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n","\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n","\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n","\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n","\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$6(CheckAnalysis.scala:193)\n","\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$6$adapted(CheckAnalysis.scala:193)\n","\tat scala.collection.immutable.Stream.foreach(Stream.scala:533)\n","\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:193)\n","\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:102)\n","\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:367)\n","\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:102)\n","\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:97)\n","\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:188)\n","\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:214)\n","\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n","\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:211)\n","\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76)\n","\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n","\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:185)\n","\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:512)\n","\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:185)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n","\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:184)\n","\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76)\n","\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n","\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n","\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$1(Dataset.scala:91)\n","\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n","\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:89)\n","\tat org.apache.spark.sql.Dataset.withPlan(Dataset.scala:3887)\n","\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1519)\n","\tat org.apache.spark.ml.clustering.KMeans.$anonfun$fit$1(KMeans.scala:350)\n","\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n","\tat scala.util.Try$.apply(Try.scala:213)\n","\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n","\tat org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:329)\n","\tat org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:272)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n","\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n","\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n","\tat py4j.Gateway.invoke(Gateway.java:282)\n","\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n","\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n","\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n","\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","\n"]},{"ename":"AnalysisException","evalue":"Column 'Item' does not exist. Did you mean one of the following? [date, features, station_id, sensor_value3];\n'Project [features#2864, unresolvedalias(UDF(cast('Item as double)), Some(org.apache.spark.sql.Column$$Lambda$4709/0x0000000101b8d040@13a20f83))]\n+- Project [date#2560, sensor_value3#2538, station_id#2552, UDF(struct()) AS features#2864]\n   +- Project [to_timestamp(date#2556, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC)) AS date#2560, sensor_value3#2538, station_id#2552]\n      +- Project [cast(date#2548 as timestamp) AS date#2556, sensor_value3#2538, station_id#2552]\n         +- Project [date#2548, sensor_value3#2538, cast(station_id#2543 as int) AS station_id#2552]\n            +- Project [cast(date#2537 as timestamp) AS date#2548, sensor_value3#2538, station_id#2543]\n               +- Project [date#2537, sensor_value3#2538, cast(station_id#2539 as int) AS station_id#2543]\n                  +- Relation [date#2537,sensor_value3#2538,station_id#2539] json\n","output_type":"error","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)","\u001B[0;32m/tmp/ipykernel_12945/1944681986.py\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m#Step 3: Clustering\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mouput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m","\u001B[0;32m/usr/lib/spark/python/pyspark/ml/base.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, dataset, params)\u001B[0m\n\u001B[1;32m    203\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 205\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    206\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    207\u001B[0m             raise TypeError(\n","\u001B[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py\u001B[0m in \u001B[0;36m_fit\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m    381\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    382\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mJM\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 383\u001B[0;31m         \u001B[0mjava_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fit_java\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    384\u001B[0m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjava_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    385\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_copyValues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py\u001B[0m in \u001B[0;36m_fit_java\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    379\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_transfer_params_to_java\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 380\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    381\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    382\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mJM\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1321\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    194\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    195\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 196\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mconverted\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    197\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    198\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mAnalysisException\u001B[0m: Column 'Item' does not exist. Did you mean one of the following? [date, features, station_id, sensor_value3];\n'Project [features#2864, unresolvedalias(UDF(cast('Item as double)), Some(org.apache.spark.sql.Column$$Lambda$4709/0x0000000101b8d040@13a20f83))]\n+- Project [date#2560, sensor_value3#2538, station_id#2552, UDF(struct()) AS features#2864]\n   +- Project [to_timestamp(date#2556, Some(yyyy-MM-dd HH:mm:ss), TimestampType, Some(Etc/UTC)) AS date#2560, sensor_value3#2538, station_id#2552]\n      +- Project [cast(date#2548 as timestamp) AS date#2556, sensor_value3#2538, station_id#2552]\n         +- Project [date#2548, sensor_value3#2538, cast(station_id#2543 as int) AS station_id#2552]\n            +- Project [cast(date#2537 as timestamp) AS date#2548, sensor_value3#2538, station_id#2543]\n               +- Project [date#2537, sensor_value3#2538, cast(station_id#2539 as int) AS station_id#2543]\n                  +- Relation [date#2537,sensor_value3#2538,station_id#2539] json\n"]}],"source":["#Step 3: Clustering\n","ouput = km.fit(train_data)"]},{"cell_type":"code","execution_count":null,"id":"1460dc80","metadata":{},"outputs":[],"source":["#Step 4: show output\n","output.summary.clusterSizes"]},{"cell_type":"code","execution_count":38,"id":"1d351ca6","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'output' is not defined","output_type":"error","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)","\u001B[0;32m/tmp/ipykernel_12945/3170420085.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclusterCenters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m","\u001B[0;31mNameError\u001B[0m: name 'output' is not defined"]}],"source":["output.clusterCenters()"]},{"cell_type":"code","execution_count":24,"id":"baa5f038","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-03-10 04:11:20--  https://storage.googleapis.com/bd522_2021/data/sensor_12.csv\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.120.207, 142.250.103.207, 142.250.159.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.120.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 62711541 (60M) [text/csv]\n","Saving to: ‘sensor_12.csv’\n","\n","sensor_12.csv       100%[===================>]  59.81M  18.2MB/s    in 4.4s    \n","\n","2024-03-10 04:11:25 (13.5 MB/s) - ‘sensor_12.csv’ saved [62711541/62711541]\n","\n","--2024-03-10 04:11:26--  https://storage.googleapis.com/bd522_2021/data/sensor_3.json\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.120.207, 142.250.103.207, 142.250.159.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.120.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 84182547 (80M) [application/json]\n","Saving to: ‘sensor_3.json’\n","\n","sensor_3.json       100%[===================>]  80.28M  19.5MB/s    in 5.5s    \n","\n","2024-03-10 04:11:32 (14.7 MB/s) - ‘sensor_3.json’ saved [84182547/84182547]\n","\n"]}],"source":["!wget https://storage.googleapis.com/bd522_2021/data/sensor_12.csv\n","!wget https://storage.googleapis.com/bd522_2021/data/sensor_3.json"]},{"cell_type":"code","execution_count":26,"id":"320c45c5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["put: `/user/dataproc/sensor_12.csv': File exists\n","put: `/user/dataproc/sensor_3.json': File exists\n"]}],"source":["!hadoop fs -put sensor_12.csv /user/dataproc/sensor_12.csv\n","!hadoop fs -put sensor_3.json /user/dataproc/sensor_3.json"]},{"cell_type":"code","execution_count":27,"id":"04c9f5a7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2 items\r\n","-rw-r--r--   2 root hadoop   62711541 2024-03-10 04:12 /user/dataproc/sensor_12.csv\r\n","-rw-r--r--   2 root hadoop   84182547 2024-03-10 04:12 /user/dataproc/sensor_3.json\r\n"]}],"source":["!hadoop fs -ls /user/dataproc"]},{"cell_type":"code","execution_count":94,"id":"37aea080","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df = spark.read.csv(\"/user/dataproc/sensor_12.csv\",\n","                    sep=\";\" ,\n","                    inferSchema=True,\n","                    header=True\n","                   )"]},{"cell_type":"code","execution_count":95,"id":"d8a1e405","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df2 = spark.read.json(\"/user/dataproc/sensor_3.json\")"]},{"cell_type":"code","execution_count":97,"id":"21d4e9f8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- date: timestamp (nullable = true)\n"," |-- sensor_value1: double (nullable = true)\n"," |-- station_id: integer (nullable = true)\n"," |-- sensor_value2: double (nullable = true)\n","\n"]}],"source":["df.printSchema()"]},{"cell_type":"code","execution_count":98,"id":"1f4c1c31","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- date: timestamp (nullable = true)\n"," |-- sensor_value3: double (nullable = true)\n"," |-- station_id: integer (nullable = true)\n","\n"]}],"source":["# Data Preparation\n","# Convert df2 column to correct type\n","df2 = df2.withColumn(\"station_id\", col('station_id').cast('integer'))\n","df2 = df2.withColumn(\"date\", col('date').cast('timestamp'))\n","df2.printSchema()"]},{"cell_type":"code","execution_count":99,"id":"9de29dfa","metadata":{},"outputs":[],"source":["df2 = df2.withColumn(\"date\", to_timestamp(df2.date, \"yyyy-MM-dd HH:mm:ss\"))"]},{"cell_type":"code","execution_count":100,"id":"789dc6d1","metadata":{},"outputs":[],"source":["df_123 = df2.join(df, [\"station_id\", \"date\"], \"inner\")"]},{"cell_type":"code","execution_count":105,"id":"214a98af","metadata":{},"outputs":[],"source":["df_all = df_123.withColumn(\"date\", to_timestamp(df_123.date, \"yyyy-MM-dd HH:mm\"))"]},{"cell_type":"code","execution_count":106,"id":"74e7ba21","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>station_id</th>\n","      <th>date</th>\n","      <th>sensor_value3</th>\n","      <th>sensor_value1</th>\n","      <th>sensor_value2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:00:00</td>\n","      <td>98.758042</td>\n","      <td>6.232350</td>\n","      <td>9.291957</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:02:00</td>\n","      <td>67.183300</td>\n","      <td>5.557534</td>\n","      <td>8.492620</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:07:00</td>\n","      <td>14.692583</td>\n","      <td>9.682279</td>\n","      <td>14.459765</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:15:00</td>\n","      <td>41.435830</td>\n","      <td>0.215575</td>\n","      <td>0.437844</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:18:00</td>\n","      <td>65.574602</td>\n","      <td>2.628964</td>\n","      <td>4.040055</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:24:00</td>\n","      <td>45.228136</td>\n","      <td>7.655527</td>\n","      <td>11.504299</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:27:00</td>\n","      <td>92.232240</td>\n","      <td>8.068260</td>\n","      <td>12.135764</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:28:00</td>\n","      <td>60.473010</td>\n","      <td>3.679941</td>\n","      <td>5.540597</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:30:00</td>\n","      <td>63.099527</td>\n","      <td>3.676593</td>\n","      <td>5.597932</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:32:00</td>\n","      <td>9.420035</td>\n","      <td>8.012445</td>\n","      <td>11.938991</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   station_id                date  sensor_value3  sensor_value1  sensor_value2\n","0           1 2018-01-01 00:00:00      98.758042       6.232350       9.291957\n","1           1 2018-01-01 00:02:00      67.183300       5.557534       8.492620\n","2           1 2018-01-01 00:07:00      14.692583       9.682279      14.459765\n","3           1 2018-01-01 00:15:00      41.435830       0.215575       0.437844\n","4           1 2018-01-01 00:18:00      65.574602       2.628964       4.040055\n","5           1 2018-01-01 00:24:00      45.228136       7.655527      11.504299\n","6           1 2018-01-01 00:27:00      92.232240       8.068260      12.135764\n","7           1 2018-01-01 00:28:00      60.473010       3.679941       5.540597\n","8           1 2018-01-01 00:30:00      63.099527       3.676593       5.597932\n","9           1 2018-01-01 00:32:00       9.420035       8.012445      11.938991"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["df_all.limit(10).toPandas()"]},{"cell_type":"code","execution_count":null,"id":"be58eea6","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":76,"id":"1280a815","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>station_id</th>\n","      <th>date</th>\n","      <th>sensor_value3</th>\n","      <th>sensor_value3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:00:00</td>\n","      <td>98.758042</td>\n","      <td>98.758042</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:01:00</td>\n","      <td>83.311504</td>\n","      <td>83.311504</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:02:00</td>\n","      <td>67.183300</td>\n","      <td>67.183300</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:03:00</td>\n","      <td>96.351818</td>\n","      <td>96.351818</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:04:00</td>\n","      <td>89.726888</td>\n","      <td>89.726888</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:05:00</td>\n","      <td>45.478606</td>\n","      <td>45.478606</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:06:00</td>\n","      <td>41.985771</td>\n","      <td>41.985771</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:07:00</td>\n","      <td>14.692583</td>\n","      <td>14.692583</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:08:00</td>\n","      <td>69.890227</td>\n","      <td>69.890227</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:09:00</td>\n","      <td>50.039344</td>\n","      <td>50.039344</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:10:00</td>\n","      <td>27.880074</td>\n","      <td>27.880074</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:11:00</td>\n","      <td>97.518710</td>\n","      <td>97.518710</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:12:00</td>\n","      <td>83.978450</td>\n","      <td>83.978450</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:13:00</td>\n","      <td>99.809396</td>\n","      <td>99.809396</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:14:00</td>\n","      <td>2.305411</td>\n","      <td>2.305411</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:15:00</td>\n","      <td>41.435830</td>\n","      <td>41.435830</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:16:00</td>\n","      <td>99.878785</td>\n","      <td>99.878785</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:17:00</td>\n","      <td>64.886567</td>\n","      <td>64.886567</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:18:00</td>\n","      <td>65.574602</td>\n","      <td>65.574602</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1</td>\n","      <td>2018-01-01 00:19:00</td>\n","      <td>30.105875</td>\n","      <td>30.105875</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    station_id                date  sensor_value3  sensor_value3\n","0            1 2018-01-01 00:00:00      98.758042      98.758042\n","1            1 2018-01-01 00:01:00      83.311504      83.311504\n","2            1 2018-01-01 00:02:00      67.183300      67.183300\n","3            1 2018-01-01 00:03:00      96.351818      96.351818\n","4            1 2018-01-01 00:04:00      89.726888      89.726888\n","5            1 2018-01-01 00:05:00      45.478606      45.478606\n","6            1 2018-01-01 00:06:00      41.985771      41.985771\n","7            1 2018-01-01 00:07:00      14.692583      14.692583\n","8            1 2018-01-01 00:08:00      69.890227      69.890227\n","9            1 2018-01-01 00:09:00      50.039344      50.039344\n","10           1 2018-01-01 00:10:00      27.880074      27.880074\n","11           1 2018-01-01 00:11:00      97.518710      97.518710\n","12           1 2018-01-01 00:12:00      83.978450      83.978450\n","13           1 2018-01-01 00:13:00      99.809396      99.809396\n","14           1 2018-01-01 00:14:00       2.305411       2.305411\n","15           1 2018-01-01 00:15:00      41.435830      41.435830\n","16           1 2018-01-01 00:16:00      99.878785      99.878785\n","17           1 2018-01-01 00:17:00      64.886567      64.886567\n","18           1 2018-01-01 00:18:00      65.574602      65.574602\n","19           1 2018-01-01 00:19:00      30.105875      30.105875"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["df_123.sort(df_123.station_id, df_123.date).limit(20).toPandas()"]},{"cell_type":"code","execution_count":50,"id":"e72f5d77","metadata":{},"outputs":[],"source":["# Transform all sensor value that lower than 0 to 0\n","df_missing = df_123.withColumn(\"sensor_value1\",\n","                               when(df_123.sensor_value1 < 0, 0) \\\n","                               .otherwise(df_123.sensor_value1)\n","                              ).withColumn(\"sensor_value2\",\n","                               when(df_123.sensor_value2 < 0, 0) \\\n","                               .otherwise(df_123.sensor_value2)\n","                              ) .withColumn(\"sensor_value3\",\n","                               when(df_123.sensor_value3 < 0, 0) \\\n","                               .otherwise(df_123.sensor_value3)\n","                              )"]},{"cell_type":"code","execution_count":49,"id":"cdf4fac2","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>summary</th>\n","      <th>station_id</th>\n","      <th>sensor_value1</th>\n","      <th>sensor_value2</th>\n","      <th>sensor_value3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>count</td>\n","      <td>1000000</td>\n","      <td>1000000</td>\n","      <td>1000000</td>\n","      <td>1000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>mean</td>\n","      <td>5.5</td>\n","      <td>4.999532123608654</td>\n","      <td>7.3990374746835865</td>\n","      <td>49.993481785964626</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>stddev</td>\n","      <td>2.8722827594107416</td>\n","      <td>2.8867280999458202</td>\n","      <td>4.347463698984681</td>\n","      <td>28.881502410793132</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>min</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>25%</td>\n","      <td>3</td>\n","      <td>2.4970664977442065</td>\n","      <td>3.656034027145632</td>\n","      <td>24.99245448966307</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>50%</td>\n","      <td>5</td>\n","      <td>4.999426406861214</td>\n","      <td>7.320367186549411</td>\n","      <td>49.99004473906103</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>75%</td>\n","      <td>8</td>\n","      <td>7.4963847645179635</td>\n","      <td>10.979495732938485</td>\n","      <td>75.00635531644248</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>max</td>\n","      <td>10</td>\n","      <td>10.16457616320874</td>\n","      <td>17.114699127085327</td>\n","      <td>100.13130454490204</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  summary          station_id       sensor_value1       sensor_value2  \\\n","0   count             1000000             1000000             1000000   \n","1    mean                 5.5   4.999532123608654  7.3990374746835865   \n","2  stddev  2.8722827594107416  2.8867280999458202   4.347463698984681   \n","3     min                   1                 0.0                 0.0   \n","4     25%                   3  2.4970664977442065   3.656034027145632   \n","5     50%                   5   4.999426406861214   7.320367186549411   \n","6     75%                   8  7.4963847645179635  10.979495732938485   \n","7     max                  10   10.16457616320874  17.114699127085327   \n","\n","        sensor_value3  \n","0             1000000  \n","1  49.993481785964626  \n","2  28.881502410793132  \n","3                 0.0  \n","4   24.99245448966307  \n","5   49.99004473906103  \n","6   75.00635531644248  \n","7  100.13130454490204  "]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["df_missing.summary().toPandas()"]},{"cell_type":"code","execution_count":56,"id":"3e63dd40","metadata":{},"outputs":[],"source":["df_all = df_123.withColumn(\"sensor_AVG\",(col(\"sensor_value1\") + col(\"sensor_value2\") + col(\"sensor_value3\"))/3)"]},{"cell_type":"code","execution_count":58,"id":"63509bb2","metadata":{},"outputs":[],"source":["df_all = df_all.select(\"station_id\", \"date\", \"sensor_AVG\")"]},{"cell_type":"code","execution_count":64,"id":"4a614455","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>station_id</th>\n","      <th>date</th>\n","      <th>sensor_AVG</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>2018-01-01</td>\n","      <td>38.165278</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>2018-01-01</td>\n","      <td>24.125779</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>2018-01-01</td>\n","      <td>29.330350</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8</td>\n","      <td>2018-01-01</td>\n","      <td>11.150519</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10</td>\n","      <td>2018-01-01</td>\n","      <td>14.357048</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>7</td>\n","      <td>2018-01-01</td>\n","      <td>38.056310</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>2018-01-01</td>\n","      <td>38.094116</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4</td>\n","      <td>2018-01-01</td>\n","      <td>14.775205</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>2018-01-01</td>\n","      <td>18.730295</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5</td>\n","      <td>2018-01-01</td>\n","      <td>24.474046</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   station_id       date  sensor_AVG\n","0           6 2018-01-01   38.165278\n","1           3 2018-01-01   24.125779\n","2           9 2018-01-01   29.330350\n","3           8 2018-01-01   11.150519\n","4          10 2018-01-01   14.357048\n","5           7 2018-01-01   38.056310\n","6           1 2018-01-01   38.094116\n","7           4 2018-01-01   14.775205\n","8           2 2018-01-01   18.730295\n","9           5 2018-01-01   24.474046"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["df_all.sort(\"date\").limit(10).toPandas()"]},{"cell_type":"code","execution_count":108,"id":"d05204e9","metadata":{},"outputs":[],"source":["train_data_sensor = df_all.groupBy(\"date\").avg(\"sensor_value1\", \"sensor_value2\", \"sensor_value3\")"]},{"cell_type":"code","execution_count":119,"id":"04a47c4b","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>avg(sensor_value1)</th>\n","      <th>avg(sensor_value2)</th>\n","      <th>avg(sensor_value3)</th>\n","      <th>features</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-01 08:40:00</td>\n","      <td>5.577034</td>\n","      <td>8.410761</td>\n","      <td>45.329286</td>\n","      <td>[5.577034191498354, 8.410761256544216, 45.3292...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2018-01-01 09:38:00</td>\n","      <td>4.670715</td>\n","      <td>6.710940</td>\n","      <td>48.550329</td>\n","      <td>[4.6707150421721195, 6.710939758210847, 48.550...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2018-01-02 09:25:00</td>\n","      <td>5.424913</td>\n","      <td>7.829558</td>\n","      <td>48.086506</td>\n","      <td>[5.42491279591634, 7.829557672221871, 48.08650...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2018-01-03 00:17:00</td>\n","      <td>6.276174</td>\n","      <td>9.336096</td>\n","      <td>51.850831</td>\n","      <td>[6.276173550873747, 9.336096400544678, 51.8508...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2018-01-05 05:50:00</td>\n","      <td>5.540920</td>\n","      <td>8.160996</td>\n","      <td>45.114480</td>\n","      <td>[5.540919642351772, 8.160996279330561, 45.1144...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2018-01-03 10:52:00</td>\n","      <td>4.903428</td>\n","      <td>7.238839</td>\n","      <td>41.668264</td>\n","      <td>[4.90342799014173, 7.238838521050797, 41.66826...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2018-01-03 14:25:00</td>\n","      <td>4.379394</td>\n","      <td>6.315839</td>\n","      <td>67.850950</td>\n","      <td>[4.379394100321763, 6.315839209064323, 67.8509...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2018-01-04 03:04:00</td>\n","      <td>4.007301</td>\n","      <td>5.716310</td>\n","      <td>37.205001</td>\n","      <td>[4.00730065250619, 5.716310194210995, 37.20500...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2018-01-04 03:44:00</td>\n","      <td>6.179993</td>\n","      <td>9.044403</td>\n","      <td>41.323637</td>\n","      <td>[6.179993402527933, 9.044403484745457, 41.3236...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2018-01-05 03:14:00</td>\n","      <td>3.745705</td>\n","      <td>5.375071</td>\n","      <td>58.365894</td>\n","      <td>[3.7457049444761084, 5.375070675045524, 58.365...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 date  avg(sensor_value1)  avg(sensor_value2)  \\\n","0 2018-01-01 08:40:00            5.577034            8.410761   \n","1 2018-01-01 09:38:00            4.670715            6.710940   \n","2 2018-01-02 09:25:00            5.424913            7.829558   \n","3 2018-01-03 00:17:00            6.276174            9.336096   \n","4 2018-01-05 05:50:00            5.540920            8.160996   \n","5 2018-01-03 10:52:00            4.903428            7.238839   \n","6 2018-01-03 14:25:00            4.379394            6.315839   \n","7 2018-01-04 03:04:00            4.007301            5.716310   \n","8 2018-01-04 03:44:00            6.179993            9.044403   \n","9 2018-01-05 03:14:00            3.745705            5.375071   \n","\n","   avg(sensor_value3)                                           features  \n","0           45.329286  [5.577034191498354, 8.410761256544216, 45.3292...  \n","1           48.550329  [4.6707150421721195, 6.710939758210847, 48.550...  \n","2           48.086506  [5.42491279591634, 7.829557672221871, 48.08650...  \n","3           51.850831  [6.276173550873747, 9.336096400544678, 51.8508...  \n","4           45.114480  [5.540919642351772, 8.160996279330561, 45.1144...  \n","5           41.668264  [4.90342799014173, 7.238838521050797, 41.66826...  \n","6           67.850950  [4.379394100321763, 6.315839209064323, 67.8509...  \n","7           37.205001  [4.00730065250619, 5.716310194210995, 37.20500...  \n","8           41.323637  [6.179993402527933, 9.044403484745457, 41.3236...  \n","9           58.365894  [3.7457049444761084, 5.375070675045524, 58.365...  "]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"source":["assembler = VectorAssembler(\n","    inputCols=[\"avg(sensor_value1)\", \"avg(sensor_value2)\", \"avg(sensor_value3)\"],\n","    outputCol=\"features\"\n",")\n","\n","train_data_with_features = assembler.transform(train_data_sensor)\n","\n","train_data_with_features.limit(10).toPandas()"]},{"cell_type":"code","execution_count":null,"id":"083e0571","metadata":{},"outputs":[],"source":["kMeans_Sensor = KMeans(k=5, seed=1, maxIter=5)"]},{"cell_type":"code","execution_count":116,"id":"cb609c3f","metadata":{},"outputs":[{"data":{"text/plain":["5"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"source":["kMeans_Sensor.setWeightCol(\"date\")\n","kMeans_Sensor.getMaxIter()"]},{"cell_type":"code","execution_count":117,"id":"e41fb956","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#Step 3: Clustering\n","output = kMeans_Sensor.fit(train_data_with_features)"]},{"cell_type":"code","execution_count":121,"id":"c002d35c","metadata":{},"outputs":[{"data":{"text/plain":["[30829, 17615, 16546, 29090, 5920]"]},"execution_count":121,"metadata":{},"output_type":"execute_result"}],"source":["#Step 4: show output\n","output.summary.clusterSizes"]},{"cell_type":"code","execution_count":123,"id":"67c05d92","metadata":{},"outputs":[{"data":{"text/plain":["[array([ 5.00625094,  7.40870835, 45.66761629]),\n"," array([ 5.00242511,  7.40364729, 60.21075404]),\n"," array([ 5.00536296,  7.40769872, 36.33459563]),\n"," array([ 4.98949563,  7.38436279, 53.15782149]),\n"," array([ 4.9864894 ,  7.38011081, 68.26669173])]"]},"execution_count":123,"metadata":{},"output_type":"execute_result"}],"source":["centers = output.clusterCenters()\n","centers"]},{"cell_type":"code","execution_count":128,"id":"c6744528","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cluster Centers: \n","center[1] ==> [ 5.00625094  7.40870835 45.66761629]\n","center[2] ==> [ 5.00242511  7.40364729 60.21075404]\n","center[3] ==> [ 5.00536296  7.40769872 36.33459563]\n","center[4] ==> [ 4.98949563  7.38436279 53.15782149]\n","center[5] ==> [ 4.9864894   7.38011081 68.26669173]\n"]}],"source":["print(\"Cluster Centers: \")\n","i = 1;\n","for center in centers:\n","    print(f\"center[{i}] ==> {center}\")\n","    i = i+1"]},{"cell_type":"code","execution_count":null,"id":"4c1a31cc","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"555ab521","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"594c0ef9","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}